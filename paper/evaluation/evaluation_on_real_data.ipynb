{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sticky-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os\n",
    "import random\n",
    "import copy\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from utils.method import read_bic_table\n",
    "\n",
    "from utils.eval import make_ref_groups\n",
    "from utils.eval import calculate_perfromance, compare_gene_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835dad35",
   "metadata": {},
   "source": [
    "# 1. Reading expressions and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serial-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs_file_t = \"data/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.log2_exprs_z_v6.tsv\"\n",
    "exprs_t= pd.read_csv(exprs_file_t,sep = \"\\t\",index_col=0)\n",
    "\n",
    "exprs_file_m = \"data/preprocessed_v6/METABRIC_1904_17Kgenes.log2_exprs_z_v6.tsv\"\n",
    "exprs_m= pd.read_csv(exprs_file_m,sep = \"\\t\",index_col=0)\n",
    "\n",
    "m_subtypes = pd.read_csv(\"data/preprocessed_v6/METABRIC_1904_17Kgenes.subtypes_and_signatures_v6.tsv\",sep = \"\\t\",index_col=0)\n",
    "m_annotation = pd.read_csv(\"data/preprocessed_v6/METABRIC_1904.annotation_v6.tsv\",sep = \"\\t\",index_col=0)\n",
    "\n",
    "t_subtypes = pd.read_csv(\"data/preprocessed_v6/TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.subtypes_and_signatures_v6.tsv\",sep = \"\\t\",index_col=0)\n",
    "t_annotation = pd.read_csv(\"data/preprocessed_v6/TCGA-BRCA_1079.Xena_TCGA_PanCan.annotation_v6.tsv\",sep = \"\\t\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2568b",
   "metadata": {},
   "source": [
    "## 1.1 Preparing ground truth samples sets for performance evaluation\n",
    "\n",
    "### Example of known_groups dictionary for TCGA-BRCA\n",
    "\n",
    "*make_ref_groups(subtypes, annotation, exprs)*\n",
    "\n",
    "**input:**\n",
    "  - subtypes - subtypes dataframe\n",
    "  - annotation - annotation dataframe\n",
    "  - exprs - expression dataframe\n",
    "  \n",
    "**returns:**\n",
    "  -  known_groups = {classificaton1:{\"subt1\":{s1,s2,...} , \"subt2\":{...}, \"subt3\":{...}, ...}, \"classi2\":{\"subtA\":{...}}, ... }\n",
    "*known_groups* is a dictionary with known sample classifications. Each classification (e.g. PAM50 or IHC or Luminal) is a dict that can conatain one or several sample sets \n",
    "  -  all_samples = {} set of all samples in expression and annotation files; necessary for computing overlap p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_groups_t, all_samples_t = make_ref_groups(t_subtypes, t_annotation,exprs_t)\n",
    "known_groups_m, all_samples_m = make_ref_groups(m_subtypes, m_annotation,exprs_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83c6ba",
   "metadata": {},
   "source": [
    "# Example 1: \n",
    "## The sructure of known_groups dict for TCGA-BRCA:\n",
    "\n",
    "We calculate performance for **classifications**:\n",
    "    * PAM50 = [Luminal, Basal, Her2, Normal]\n",
    "    * Intrinsic = [Luminal, Basal, Her2, Normal, Claudin-low]\n",
    "    * PAM50_AB =  [LumA, LumB, Basal, Her2, Normal]\n",
    "    * SCMOD2 = [ER-/HER2-, ER+/HER2- High Prolif, ER+/HER2- Low Prolif,  HER2+]\n",
    "    * IHC = [IHC_HER2, IHC_ER, IHC_PR, IHC_TNBC]\n",
    "And for **isolated sample sets** corresponding to Luminal, Basal, LumA, NEC subtypes etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in known_groups_t.keys():\n",
    "    if len(known_groups_t[cl].keys())>1:\n",
    "        print(\"classification\", cl)\n",
    "        print(\"\\tsbtypes:\",\" \".join(known_groups_t[cl].keys()))\n",
    "    else:\n",
    "        print(\" classification\", cl, \"(individual subtype)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9a0b5",
   "metadata": {},
   "source": [
    "# Example 2: \n",
    "## evaluation of the resulting sample set (on the example of UnPaSt file) \n",
    "reading the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"results_on_real_data_WGCNA2/TCGA.seed=670487.bin=kmeans,pval=0.01,clust=WGCNA,direction=UP-DOWN,ds=3,dch=0.995,max_power=10,precluster=True.biclusters.tsv\"\n",
    "result = read_bic_table(file) # reading UnPaSt outputs\n",
    "print(\"sample clusters: \", result.shape[0])\n",
    "# drop clusters too small with < 5 samples\n",
    "result = result.loc[result[\"samples\"].apply(lambda x: len(x))>=5,:]\n",
    "print(\"sample clusters: \", result.shape[0])\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fd8068",
   "metadata": {},
   "source": [
    "* ensure that results file is a dataframe with \"samples\" column\n",
    "* each row in samples column must contain a non-empty set of samples\n",
    "## performance evaluation\n",
    "* requires *known_groups* dict and *all_samples* set  \n",
    "     - using *make_ref_groups()* is recommened for this breast cancer analysis\n",
    "     - alternatively, *known_groups* dict and *all_samples* can be created manually\n",
    "* if samples in (bi)clusters do not match *all_samples* set, trho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e618ef",
   "metadata": {},
   "source": [
    "*calculate_perfromance(bi_clusters_df, annotation, exprs)*\n",
    "\n",
    "**input:**\n",
    "  - bi_clusters_df - a dataframe with sample clusters (sets in \"sample\" column)\n",
    "  - *known_groups* is a dictionary with known sample classifications. Each classification (e.g. PAM50 or IHC or Luminal) is a dict that can conatain one or several sample sets \n",
    "  - *all_samples* = {} set of all samples in expression and annotation files; necessary for computing overlap p-values\n",
    "  \n",
    "**returns:**\n",
    "  - performances - *pandas.Series* with overall perforamnce for each classification from *known_groups* \n",
    "  - best_matches - a dataframe with information about the best matching (bi)cluster for each sample set from *known_groups* (helpful for debugging and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "performances, best_matches = calculate_perfromance(result, known_groups_t,all_samples_t)\n",
    "performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03243bab",
   "metadata": {},
   "source": [
    "# 2. Evaluation of the results obtained with different parameters\n",
    "(UnPaSt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting 5 seeds for probabilistic methods \n",
    "n_runs = 5\n",
    "seeds = []\n",
    "random.seed(42)\n",
    "for i in range(n_runs):\n",
    "    seeds.append(random.randint(0,1000000))\n",
    "print(\"generate \",n_runs,\" seeds\",seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "subt_t = [] # Perfoemances for TCGA-BRCA\n",
    "subt_m = [] # Perfoemances for METABRIC\n",
    "clustering_similarities = [] # Similarities of gene clusters found in TCGA and METABRIC\n",
    "\n",
    "# UnPaSt parameters \n",
    "from run_unpast import run\n",
    "rpath=\"/home/olya/anaconda3/envs/r4_env/bin/\"\n",
    "out_dir= \"results_on_real_data_WGCNA2/\"\n",
    "basename_t = \"TCGA\"\n",
    "basename_m = \"METABRIC\" \n",
    "pvals = [0.05,0.01,0.005,0.001]\n",
    "bin_methods = [\"kmeans\",\"GMM\",\"ward\"] \n",
    "directions =  [[\"UP\",\"DOWN\"],[\"BOTH\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea7460",
   "metadata": {},
   "source": [
    "Because UnPaSt parameters are different for Louvain and WGCNA feature clusterings, \n",
    "we run it for each clust_method in a separate *for* loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-flush",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Louvain \n",
    "out_dir= \"results_on_real_data_WGCNA2//\"\n",
    "modularities = [0,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "subt_t = []\n",
    "subt_m = []\n",
    "clustering_similarities = []\n",
    "\n",
    "\n",
    "for pval in pvals:\n",
    "    for bin_method in bin_methods:\n",
    "        for d in directions:\n",
    "            for m in modularities:\n",
    "                # save parameters as a ;-separated string\n",
    "                params = \"bin=\"+bin_method+\";pval=\"+str(pval)\n",
    "                params += \";clust=\"+\"Louvain\"+\";direction=\"+\"-\".join(d)+\";m=\"+str(m)\n",
    "                print()\n",
    "                for r in range(n_runs):\n",
    "                    seed = seeds[r]\n",
    "                    params_dict = {\"parameters\":params, \"seed\":seed,\"run\":r}\n",
    "                    ### running TCGA or reading results\n",
    "                    try:\n",
    "                        t0 = time()\n",
    "                        fname = out_dir+basename_t+\".seed=\"+str(seed)+\\\n",
    "                        \".bin=\"+bin_method +\",pval=\"+str(pval)+\",clust=Louvain\"+\",direction=\"+\"-\".join(d)+\",m=\"+str(m)+\".biclusters.tsv\"\n",
    "                        result_t = read_bic_table(fname)\n",
    "                        \"\"\"result_t = run_DESMOND(exprs_file_t, basename_t, out_dir=out_dir,\n",
    "                                                    save=True, load = True,\n",
    "                                                    ceiling = 3,\n",
    "                                                    min_n_samples = 5,\n",
    "                                                    bin_method = bin_method, pval = pval,\n",
    "                                                    clust_method = \"Louvain\",\n",
    "                                                    similarity_cutoffs = similarity_cutoffs,\n",
    "                                                    seed = seed,\n",
    "                                                    verbose = False)\n",
    "                                                    \"\"\"\n",
    "                        time_t = time()-t0\n",
    "                        # find the best matches between TCGA biclusters and subtypes\n",
    "                        # and calculate overall performance == weighted sum of Jaccard indexes\n",
    "                        performance_t,bm_dict_t = calculate_perfromance(result_t, known_groups_t,all_samples_t,\n",
    "                                                                        performance_measure=\"ARI\")\n",
    "                        performance_t = performance_t.to_dict()\n",
    "                        performance_t.update(params_dict)\n",
    "                        performance_t[\"time\"] = time_t\n",
    "                        subt_t.append(performance_t)\n",
    "                        t_failed = False\n",
    "                    except:\n",
    "                        print(\"TCGA biclustering failed with \",seed,  pval,bin_method ,file = sys.stderr)\n",
    "                        print(fname)\n",
    "                        t_failed = True\n",
    "                        subt_t.append({params_dict})\n",
    "\n",
    "                    ### running METABRIC or reading results\n",
    "                    try:\n",
    "                        t0 = time()\n",
    "                        fname = out_dir+basename_m+\".seed=\"+str(seed)+\\\n",
    "                        \".bin=\"+bin_method +\",pval=\"+str(pval)+\",clust=Louvain\"+\",direction=\"+\"-\".join(d)+\",m=\"+str(m)+\".biclusters.tsv\"\n",
    "                        result_m = read_bic_table(fname)\n",
    "                        \"\"\"result_m = run_DESMOND(exprs_file_m, basename_m, out_dir=out_dir,\n",
    "                                                    save=True, load = True,\n",
    "                                                    ceiling = 3,\n",
    "                                                    min_n_samples = 5,\n",
    "                                                    bin_method = bin_method, pval = pval,\n",
    "                                                    clust_method = \"Louvain\",\n",
    "                                                    similarity_cutoffs = similarity_cutoffs,\n",
    "                                                    seed = seed,\n",
    "                                                    verbose = False)\"\"\"\n",
    "                        time_m = time()-t0\n",
    "                        # find the best matches between METABRIC biclusters and subtypes\n",
    "                        # and calculate overall performance == weighted sum of Jaccard indexes\n",
    "                        performance_m,bm_dict_m = calculate_perfromance(result_m, known_groups_m,all_samples_m,\n",
    "                                                                        performance_measure=\"ARI\")\n",
    "                        performance_m = performance_m.to_dict()\n",
    "                        performance_m.update(params_dict)\n",
    "                        performance_m[\"time\"] = time_m\n",
    "                        subt_m.append(performance_m)\n",
    "                        m_failed = False\n",
    "                    except:\n",
    "                        print(\"METABRIC biclustering failed with \",seed,  pval,bin_method ,file = sys.stderr)\n",
    "                        print(fname)\n",
    "                        m_failed = True\n",
    "                        subt_m.append(params_dict)\n",
    "                    print(params,seed, round(performance_t[\"PAM50\"],3),round(performance_m[\"PAM50\"],3))    \n",
    "                    # compare clustering results - only if gene sets are defined for each cluster\n",
    "                    if not (t_failed or m_failed): \n",
    "                        N = exprs_m.shape[0]\n",
    "                        clust_sim, bm, bm2 = compare_gene_clusters(result_t,result_m, N)                    \n",
    "                    else:\n",
    "                        clust_sim = {}\n",
    "                    clust_sim.update(params_dict)\n",
    "                    clustering_similarities.append(clust_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328fec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18f114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clust_methods = [\"WGCNA\"]\n",
    "dss = [0,1,2,3]\n",
    "dchs = [0.95,0.995]\n",
    "cseed = 0\n",
    "\n",
    "pc = True\n",
    "\n",
    "for pval in pvals:\n",
    "    for ds in dss:\n",
    "        for dch in dchs:\n",
    "            for d in directions:\n",
    "                for clust_method in clust_methods:\n",
    "                    for bin_method in bin_methods:\n",
    "                        # save parameters as a ;-separated string\n",
    "                        params = \"bin=\"+bin_method+\";pval=\"+str(pval)+\";direction=\"+str(\"-\".join(d))\n",
    "                        params += \";clust=\"+clust_method+\";dch=\"+str(dch)+\";ds=\"+str(ds)+\";preClustering=T\"\n",
    "                        print(params)\n",
    "                        biclusters_t = []\n",
    "                        biclusters_m = []\n",
    "                        for r in range(n_runs):\n",
    "                            seed = seeds[r]\n",
    "                            #print(\"run\",run,bin_method,pval,m,seed)\n",
    "                            params_dict = {\"parameters\":params, \"seed\":seed,\"run\":r}\n",
    "\n",
    "                            ### running TCGA or reading results\n",
    "                            try:\n",
    "                                t0 = time()\n",
    "                                fname = out_dir+basename_t+\".seed=\"+str(seed)+\".bin=\"+bin_method +\",pval=\"+str(pval)+\",clust=WGCNA,direction=\"+str(\"-\".join(d))+\",ds=\"+str(ds)+\",dch=\"+str(dch)+\",max_power=10,precluster=True\"+\".biclusters.tsv\"\n",
    "                                try:\n",
    "                                    result_t = read_bic_table(fname)\n",
    "                                except:\n",
    "                                    print(\"not found\")\n",
    "                                    \"\"\"result_t = run(exprs_file_t, basename_t, out_dir=out_dir,\n",
    "                                                                save=True, load = True,\n",
    "                                                                min_n_samples = 5,\n",
    "                                                                bin_method = bin_method, pval = pval,\n",
    "                                                                directions = d,\n",
    "                                                                clust_method = clust_method,\n",
    "                                                                precluster=pc,\n",
    "                                                                ds=ds,dch=dch,\n",
    "                                                                rpath=rpath,\n",
    "                                                                seed = seed,\n",
    "                                                                verbose = False)\n",
    "                                                                \n",
    "                                    \"\"\"\n",
    "                                performance_t,bm_dict_t = calculate_perfromance(result_t, known_groups_t,\n",
    "                                                                                all_samples_t,\n",
    "                                                                                performance_measure=\"ARI\")\n",
    "                                performance_t = performance_t.to_dict()\n",
    "                                performance_t.update(params_dict)\n",
    "                                performance_t[\"time\"] = time_t\n",
    "                                subt_t.append(performance_t)\n",
    "                                t_failed = False\n",
    "                            except:\n",
    "                                print(\"TCGA biclustering failed with \",seed,  pval,bin_method ,file = sys.stderr)\n",
    "                                print(fname)\n",
    "                                t_failed = True\n",
    "                                subt_t.append({params_dict})\n",
    "                            \n",
    "                            ### running METABRIC or reading results\n",
    "                            try:\n",
    "                                t0 = time()\n",
    "                                fname = out_dir+basename_m+\".seed=\"+str(seed)+\".bin=\"+bin_method +\",pval=\"+str(pval)+\",clust=WGCNA,direction=\"+str(\"-\".join(d))+\",ds=\"+str(ds)+\",dch=\"+str(dch)+\",max_power=10,precluster=True\"+\".biclusters.tsv\"\n",
    "                                try:\n",
    "                                    result_m = read_bic_table(fname)\n",
    "                                except:\n",
    "                                    print(fname)\n",
    "                                    \"\"\"result_m = run(exprs_file_m, basename_m, out_dir=out_dir,\n",
    "                                                                save=True, load = True,\n",
    "                                                                min_n_samples = 5,\n",
    "                                                                bin_method = bin_method, pval = pval,\n",
    "                                                                directions = d,\n",
    "                                                                clust_method = clust_method,\n",
    "                                                                precluster=pc,\n",
    "                                                                ds=ds,dch=dch,\n",
    "                                                                rpath=rpath,\n",
    "                                                                seed = seed,\n",
    "                                                                verbose = False)\n",
    "                                    \"\"\"\n",
    "                                time_m = time()-t0\n",
    "                                # find the best matches between METABRIC biclusters and subtypes\n",
    "                                # and calculate overall performance == weighted sum of Jaccard indexes\n",
    "                                performance_m,bm_dict_m = calculate_perfromance(result_m, known_groups_m,all_samples_m,\n",
    "                                                                                performance_measure=\"ARI\")\n",
    "                                performance_m = performance_m.to_dict()\n",
    "                                performance_m.update(params_dict)\n",
    "                                performance_m[\"time\"] = time_m\n",
    "                                subt_m.append(performance_m)\n",
    "                                m_failed = False\n",
    "                            except:\n",
    "                                print(\"METABRIC biclustering failed with \",seed,  pval,bin_method ,file = sys.stderr)\n",
    "                                print(fname)\n",
    "                                m_failed = True\n",
    "                                subt_m.append(params_dict)\n",
    "                            print(params,seed, round(performance_t[\"PAM50\"],3),round(performance_m[\"PAM50\"],3))    \n",
    "                            # compare clustering results - only if gene sets are defined for each cluster\n",
    "                            if not (t_failed or m_failed): \n",
    "                                N = exprs_m.shape[0]\n",
    "                                clust_sim, bm, bm2 = compare_gene_clusters(result_t,result_m, N)                    \n",
    "                            else:\n",
    "                                clust_sim = {}\n",
    "                            clust_sim.update(params_dict)\n",
    "                            clustering_similarities.append(clust_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3b14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "940d5621",
   "metadata": {},
   "source": [
    "### Saving method performaces for all parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(clustering_similarities).to_csv(\"UnPaSt_similarities.tsv\",sep = \"\\t\")\n",
    "pd.DataFrame.from_records(subt_t).to_csv(\"UnPaSt_TCGA.tsv\",sep = \"\\t\")\n",
    "pd.DataFrame.from_records(subt_m).to_csv(\"UnPaSt_METABRIC.tsv\",sep = \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-values",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c433dcaf",
   "metadata": {},
   "source": [
    "## 3. Selecting parameters for TCGA and METABRIC\n",
    "* max. performance for PAM50 classification\n",
    "* TCGA-BRCA = 0.75\n",
    "* METABRIC = 0.76\n",
    "\n",
    "### 4. Optimal parameters selection\n",
    "\n",
    "* minimal rank sum for TCGA and METABRIC\n",
    "* slightly inferior compared to \"best\" parameter combination for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc2e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnPaSt\tbest mean rank: 23.5 top-%: 6.12\n",
      "\topt. parameters:\n",
      "\t\tbin=kmeans;pval=0.01;direction=UP-DOWN;clust=WGCNA;dch=0.995;ds=3;preClustering=T\n",
      "\tperformance w. optimized:\tTCGA-BRCA:0.72\tMETABRIC:0.76\n",
      "\tbest parameters TCGA-BRCA:\t0.75\n",
      "\t\tbin=ward;pval=0.01;direction=UP-DOWN;clust=WGCNA;dch=0.95;ds=3;preClustering=T\n",
      "\tbest parameters METABRIC:\t0.76\n",
      "\t\tbin=kmeans;pval=0.05;direction=UP-DOWN;clust=WGCNA;dch=0.995;ds=3;preClustering=T\n"
     ]
    }
   ],
   "source": [
    "ds1 = \"TCGA-BRCA\"\n",
    "ds2 = \"METABRIC\"\n",
    "method = \"UnPaSt\"\n",
    "performance_col = \"PAM50\"\n",
    "\n",
    "df1 = pd.read_csv(\"UnPaSt_TCGA.tsv\",sep = \"\\t\",index_col =0)\n",
    "df2 = pd.read_csv(\"UnPaSt_METABRIC.tsv\",sep = \"\\t\",index_col =0)\n",
    "\n",
    "\n",
    "#if \"seed\" in df1.columns or \"seed\" in df2.columns:\n",
    "df1 = df1.groupby(\"parameters\").agg(\"mean\")\n",
    "df2 = df2.groupby(\"parameters\").agg(\"mean\")\n",
    "\n",
    "df1 = df1.sort_values(by=performance_col,ascending= False)\n",
    "df2 = df2.sort_values(by=performance_col,ascending= False)\n",
    "\n",
    "df1[\"rank\"] =df1[performance_col].rank(ascending= False)\n",
    "df2[\"rank\"] =df2[performance_col].rank(ascending= False)\n",
    "mean_ranks = (df1[\"rank\"]+df2[\"rank\"])*0.5\n",
    "mean_ranks = mean_ranks.sort_values()\n",
    "best_mean_rank = mean_ranks.head(1)[0]\n",
    "optimized_params = mean_ranks[mean_ranks == best_mean_rank].index.values\n",
    "print(method+\"\\tbest mean rank:\",best_mean_rank, \"top-%:\", round(best_mean_rank/mean_ranks.shape[0],4)*100)\n",
    "\n",
    "print(\"\\topt. parameters:\\n\\t\\t\"+\"\\n\\t\\t\".join(optimized_params) )\n",
    "\n",
    "# perfromance with optimized parameters\n",
    "opt_perf1 = df1.loc[optimized_params,performance_col].sort_values(ascending= False)[0]\n",
    "opt_perf2 = df2.loc[optimized_params,performance_col].sort_values(ascending= False)[0]\n",
    "print(\"\\tperformance w. optimized:\\t%s:%.2f\\t%s:%.2f\"%(ds1,opt_perf1,ds2,opt_perf2))\n",
    "# best perfromance \n",
    "best_perf1 = df1.loc[:,performance_col].sort_values(ascending= False)\n",
    "best_perf1 = best_perf1[0]\n",
    "best_param1 =  df1.loc[df1[performance_col]==best_perf1,:].index.values\n",
    "print(\"\\tbest parameters %s:\\t%.2f\"%(ds1,best_perf1))\n",
    "print(\"\\t\\t\"+\"\\n\\t\\t\".join(best_param1))\n",
    "\n",
    "best_perf2 = df2.loc[:,performance_col].sort_values(ascending= False)\n",
    "best_perf2 = best_perf2[0]\n",
    "best_param2 =  df2.loc[df2[performance_col]==best_perf2,:].index.values\n",
    "print(\"\\tbest parameters %s:\\t%.2f\"%(ds2,best_perf2))\n",
    "print(\"\\t\\t\"+\"\\n\\t\\t\".join(best_param2))\n",
    "\n",
    "#print(method, df1.shape[0], df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb71a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-offering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
