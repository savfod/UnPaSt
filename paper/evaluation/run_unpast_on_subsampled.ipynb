{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import random\n",
    "import copy\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.method import read_bic_table\n",
    "from utils.eval import find_best_matches, make_known_groups, find_best_matching_biclusters\n",
    "import glob\n",
    "sys.path.insert(0, './evaluation/subsampling')\n",
    "import settings\n",
    "\n",
    "from run_desmond import run_DESMOND\n",
    "\n",
    "\n",
    "def make_ref_groups(subtypes, annotation,exprs):\n",
    "    # prepared a dict of subtype classifications {\"class1\":{\"subt1\":[],\"subt2\":[]},\"class2\":{\"subtA\":[],\"subtB\":[]}}\n",
    "    all_samples = set(exprs.columns.values)\n",
    "    pam50 = make_known_groups(subtypes, exprs,target_col = \"PAM50\",verbose=False)\n",
    "    lum = {}\n",
    "    lum[\"Luminal\"] = pam50[\"LumA\"].union(pam50[\"LumB\"])\n",
    "    scmod2 = make_known_groups(subtypes, exprs,target_col = 'SCMOD2',verbose=False)\n",
    "    claudin = {} \n",
    "    claudin[\"Claudin-low\"] = set(subtypes.loc[subtypes['claudin_low']==1,:].index.values).intersection(all_samples)\n",
    "    \n",
    "    ihc = {}\n",
    "    for x in [\"IHC_HER2\",\"IHC_ER\",\"IHC_PR\"]:\n",
    "        ihc[x] = set(annotation.loc[annotation[x]==\"Positive\",:].index.values)\n",
    "    ihc[\"IHC_TNBC\"] = set(annotation.loc[annotation[\"IHC_TNBC\"]==1,:].index.values)\n",
    "    \n",
    "    known_groups = {\"PAM50\":pam50,\"Luminal\":lum,\"Claudin-low\":claudin,\"SCMOD2\":scmod2,\"IHC\":ihc}\n",
    "    \n",
    "    freqs = {}\n",
    "    N =  exprs.shape[1]\n",
    "    for classification in known_groups.keys():\n",
    "        for group in known_groups[classification].keys():\n",
    "            n = len(known_groups[classification][group])\n",
    "            freqs[group] = n/N\n",
    "            \n",
    "    return known_groups, freqs\n",
    "\n",
    "def calculate_perfromance(results, known_groups, freqs, all_samples,\n",
    "                          classifications={\"Intrinsic\":[\"Luminal\",\"Basal\",\"Her2\",\"Normal\",\"Claudin-low\"]}):\n",
    "    # finds best matches for each subtype, calcuates J per subtype and overall performance\n",
    "    N = len(all_samples)\n",
    "    best_matches = []\n",
    "    \n",
    "    for classification in known_groups.keys():\n",
    "        bm = find_best_matches(results,known_groups[classification],all_samples,FDR=0.05,verbose = False)\n",
    "        best_matches.append(bm)\n",
    "            \n",
    "    best_matches = pd.concat(best_matches, axis=0)\n",
    "    best_matches = best_matches[\"J\"].to_dict()\n",
    "    \n",
    "    for cl_name in classifications.keys():\n",
    "        overall_performance = 0\n",
    "        norm_factor = 0\n",
    "        for group in classifications[cl_name]:\n",
    "            overall_performance += best_matches[group]*freqs[group]\n",
    "            norm_factor +=freqs[group]\n",
    "        overall_performance = overall_performance/norm_factor \n",
    "        best_matches[\"overall_performance_\"+cl_name] = overall_performance\n",
    "    return best_matches\n",
    "\n",
    "def compare_gene_clusters(tcga_result,metabric_result, N):\n",
    "    # N - total number of genes\n",
    "    # finds best matched TCGA -> METABRIC and METABRIC -> TCGA\n",
    "    # calculates % of matched clusterst, number of genes in matched cluster, \n",
    "    # and the average J index for best matches \n",
    "    bm = find_best_matching_biclusters(tcga_result,metabric_result, N)\n",
    "    bm = bm.dropna()\n",
    "    bm2 = find_best_matching_biclusters(metabric_result, tcga_result, N)\n",
    "    bm2 = bm2.dropna()\n",
    "    \n",
    "    bm = bm.loc[bm[\"n_shared\"]>1,:].sort_values(by=\"n_shared\",ascending = False)\n",
    "    bm2 = bm2.loc[bm2[\"n_shared\"]>1,:].sort_values(by=\"n_shared\",ascending = False)\n",
    "    \n",
    "    clust_similarity = {}\n",
    "    # number of biclusters \n",
    "    clust_similarity[\"n_1\"] = tcga_result.shape[0]\n",
    "    clust_similarity[\"n_2\"] = metabric_result.shape[0]\n",
    "    #print(\"% matched biclusters:\",bm.shape[0]/tcga_result.shape[0],bm2.shape[0]/metabric_result.shape[0])\n",
    "    clust_similarity[\"percent_matched_1\"] = bm.shape[0]/tcga_result.shape[0]\n",
    "    clust_similarity[\"percent_matched_2\"] = bm2.shape[0]/metabric_result.shape[0]\n",
    "    #print(\"n matched genes:\",bm.loc[:,\"n_shared\"].sum(),bm2.loc[:,\"n_shared\"].sum())\n",
    "    clust_similarity[\"n_shared_genes_1\"] = bm.loc[:,\"n_shared\"].sum()\n",
    "    clust_similarity[\"n_shared_genes_2\"] = bm2.loc[:,\"n_shared\"].sum()\n",
    "    #print(\"avg. J:\",bm.loc[:,\"J\"].mean(),bm2.loc[:,\"J\"].mean())\n",
    "    clust_similarity[\"avg_bm_J_1\"] = bm.loc[:,\"J\"].mean()\n",
    "    clust_similarity[\"avg_bm_J_2\"] = bm2.loc[:,\"J\"].mean()\n",
    "\n",
    "    return clust_similarity, bm, bm2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_subsampled(dataset_name, subsample_factor, min_samples, seeds=None):\n",
    "    assert seeds is None or isinstance(seeds, list)\n",
    "    if seeds is None:\n",
    "        seed_folders = glob.glob(os.path.join(settings.OUTPUT_FOLDER, dataset_name, 'seed=*', f'factor={subsample_factor}', f'min_samples={min_samples}'))\n",
    "        \n",
    "        print(f'Found {len(seed_folders)} seeds for {dataset_name} with factor {subsample_factor} and min_samples {min_samples}')\n",
    "    print(f'Found {len(seed_folders)}. {seed_folders}')\n",
    "    for seed_folder in seed_folders:\n",
    "        print('Running unpast for seed_folder', seed_folder)\n",
    "        for x in seed_folder.split('/'):\n",
    "            if x.startswith('seed='):\n",
    "                seed = x.replace('seed=', '')\n",
    "                break\n",
    "        subtype_path = os.path.join(seed_folder, 'subtypes.tsv')\n",
    "        annoation_path = os.path.join(seed_folder, 'annotation.tsv')\n",
    "        expression_path = os.path.join(seed_folder, 'expression.tsv')\n",
    "        \n",
    "        subtype_df = pd.read_csv(subtype_path,sep = \"\\t\",index_col=0)\n",
    "        annoation_df = pd.read_csv(annoation_path,sep = \"\\t\",index_col=0)\n",
    "        exprs_df = pd.read_csv(expression_path,sep = \"\\t\",index_col=0)\n",
    "        \n",
    "        clustering_similarities_df = _run_unpast(dataset_name, expression_path, subtype_df, annoation_df, exprs_df)\n",
    "        \n",
    "        filename = os.path.join(seed_folder, f'unpast_result_seed={seed}.tsv')\n",
    "        print('Saving outfile', filename)\n",
    "        clustering_similarities_df.to_csv(filename, sep='\\t')\n",
    "    return\n",
    "        \n",
    "\n",
    "def _run_unpast(dataset_name, expression_path, subtype_df, annoation_df, exprs_df):\n",
    "    classifications={\"Intrinsic\":[\"Luminal\",\"Basal\",\"Her2\",\"Normal\",\"Claudin-low\"],\n",
    "                \"SCMOD2\":[\"ER-/HER2-\",\"ER+/HER2- Low Prolif\",\"ER+/HER2- High Prolif\",\"HER2+\"],\n",
    "                \"IHC\":[\"IHC_TNBC\",\"IHC_ER\",\"IHC_HER2\",\"IHC_PR\"]}\n",
    "\n",
    "    known_groups, freqs = make_ref_groups(subtype_df, annoation_df, exprs_df)\n",
    "    \n",
    "    n_runs = 5\n",
    "    seeds = []\n",
    "    random.seed(101)\n",
    "    for i in range(n_runs):\n",
    "        seeds.append(random.randint(0, 1000000))\n",
    "    print(\"generate \",n_runs,\" seeds\",seeds)\n",
    "\n",
    "    best_params = settings.UNPAST_BEST_PARAMS['OVERALL']\n",
    "\n",
    "    ### Louvain \n",
    "    out_dir= '/'.join(expression_path.split('/')[:-1])\n",
    "    out_dir = os.path.join(out_dir, ';'.join(['='.join([str(a), str(b)]) for a, b in settings.UNPAST_BEST_PARAMS['OVERALL'].items()]))\n",
    "    modularities = [0,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    print(out_dir)\n",
    "    if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "            \n",
    "    subt = []\n",
    "    clustering_similarities = []\n",
    "    for run in range(n_runs):\n",
    "        seed = seeds[run]\n",
    "        print(\"Running unpast: Iteration \",run, 'with', best_params, expression_path)\n",
    "\n",
    "        # save parameters as a ;-separated string\n",
    "        params = f\"bin={best_params['bin_method']};pval={best_params['pval']}\"\n",
    "        params += f\";clust={best_params['clust_method']};ds={best_params['ds']}\"\n",
    "        params_dict = {\"parameters\":params, \"seed\":seed,\"run\":run}\n",
    "\n",
    "        ### running TCGA or reading results\n",
    "        try:\n",
    "            result = run_DESMOND(\n",
    "                expression_path, \n",
    "                dataset_name, \n",
    "                **best_params,\n",
    "                out_dir=out_dir,\n",
    "                save=True, \n",
    "                load = True,\n",
    "                ceiling =3,\n",
    "                min_n_samples = 5,\n",
    "                cluster_binary=False,\n",
    "                seed = seed,\n",
    "                verbose = False, \n",
    "                plot_all = False,\n",
    "                merge = 1)\n",
    "            # find the best matches between TCGA biclusters and subtypes\n",
    "            # and calculate overall performance == weighted sum of Jaccard indexes\n",
    "            performance = calculate_perfromance(result, known_groups,\n",
    "                                                  freqs, set(exprs_df.columns.values),\n",
    "                                                  classifications=classifications)\n",
    "            performance.update(params_dict)\n",
    "            performance[\"time\"] = time\n",
    "            subt.append(performance)\n",
    "            failed = False\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"biclustering failed with \",seed, params,file = sys.stderr)\n",
    "            failed = True\n",
    "            subt.append(params_dict)\n",
    "\n",
    "    return pd.DataFrame.from_records(subt)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95938e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_on_subsampled('METABRIC', .5, 10)\n",
    "run_on_subsampled('TCGA', .5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b488a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_subsampled('METABRIC', .3, 10)\n",
    "run_on_subsampled('TCGA', .3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7332f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_subsampled('METABRIC', .1, 10)\n",
    "run_on_subsampled('TCGA', .1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_subsampled('METABRIC', .05, 0)\n",
    "run_on_subsampled('TCGA', .05, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de363de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_subsampled('METABRIC', .4, 10)\n",
    "run_on_subsampled('TCGA', .4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_subsampled('METABRIC', .2, 10)\n",
    "run_on_subsampled('TCGA', .2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983d4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24dc187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encore2",
   "language": "python",
   "name": "encore2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
